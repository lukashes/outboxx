# Outboxx Development Plan

## Development Philosophy: Function First, Optimize Later

Outboxx follows a pragmatic development approach:
1. **Build functional library** with complete feature set
2. **Conduct load testing** to identify bottlenecks
3. **Optimize performance** based on real-world data
4. **Interface design takes priority** over implementation details

This ensures we build the right thing before we build it right.

## Current Status: Streaming Replication Complete âœ…

**Major Achievements:**
- âœ… **PostgreSQL Streaming Replication**: Binary pgoutput protocol with real-time push
- âœ… **End-to-End Pipeline**: Complete PostgreSQL â†’ Kafka message flow
- âœ… **Memory Safety**: Proper Zig allocator usage and error handling
- âœ… **Comprehensive Testing**: Unit, integration, and E2E tests with real services
- âœ… **Multi-Stream Configuration**: TOML-based configuration with validation
- âœ… **Development Environment**: Nix-based isolated setup with Docker Compose
- âœ… **High Performance**: ~105k events/sec, <10 MB memory (70% of Debezium throughput)

### Phase 1: Foundation âœ… (COMPLETED)
- âœ… Project structure and build.zig with Nix environment
- âœ… PostgreSQL connector with libpq integration
- âœ… Logical replication client for WAL stream connection
- âœ… WAL records decoding and parsing with test_decoding plugin
- âœ… Comprehensive integration tests with real PostgreSQL
- âœ… Memory-safe implementation with proper error handling

### Phase 2: Data Processing âœ… (COMPLETED)
- âœ… Message formatting with JSON serialization
- âœ… TOML configuration support with validation
- âœ… Multi-stream support for different tables
- âœ… Relation registry for table metadata (pgoutput)
- ðŸ“‹ Schema registry for complex type handling
- ðŸ“‹ Advanced data transformations

### Phase 3: Kafka Integration âœ… (COMPLETED)
- âœ… Kafka producer with librdkafka integration
- âœ… Basic partitioning by table
- âœ… Integration tests with embedded Kafka consumer
- ðŸ“‹ Advanced partitioning strategies
- ðŸ“‹ Error handling with retry/dead letter queue
- ðŸ“‹ Performance metrics and monitoring

### Phase 4: Operations âœ… (COMPLETED)
- âœ… LSN tracking with at-least-once delivery guarantee
- âœ… Structured logging with std.log
- âœ… Graceful shutdown with signal handlers
- âœ… Configuration validation on startup
- âœ… Fail-fast error handling with supervisor restart

## Future Development Phases

### Phase 5: Advanced Features ðŸ“‹ (PLANNED)
- Schema registry integration for complex types
- Table/column filtering at processor level
- Advanced data transformations and enrichment
- Snapshot support for initial data load

### Phase 6: Production Features ðŸ¢ (PLANNED)
Enterprise-ready capabilities:
- Monitoring, metrics, and operational visibility
- High availability and failover scenarios
- Advanced configuration options
- Performance tuning and optimization

## Learning Goals for Zig
- Memory management with allocators
- C interop with libpq/librdkafka
- Async/await for network operations
- Error handling with error unions
- Performance optimization with comptime

## Implementation Notes

### Key Dependencies
- **libpq** âœ… - PostgreSQL streaming replication protocol (integrated)
- **librdkafka** âœ… - High-performance Kafka client (integrated)
- **zig-toml** âœ… - TOML configuration parsing (integrated)
- **zig std.json** âœ… - JSON serialization (using standard library)

### Architecture Decisions
- Use Zig's built-in allocators for memory management
- Leverage C interop for mature libraries (libpq, librdkafka)
- Event-driven I/O with poll() for efficient network handling
- Fail-fast error handling with supervisor-based restart
- Use error unions for robust error handling throughout the pipeline

### Performance Achievements
- Binary protocol (pgoutput) eliminates text parsing overhead
- Event-driven I/O reduces CPU usage from 98% to <10%
- Arena Allocator for automatic batch memory cleanup
- Async flush/commit in background thread reduces blocking operations
- **Current throughput: ~105k events/sec** (progress: 60k â†’ 85k â†’ 105k, target: 150k to match Debezium)
- Memory footprint: <10 MB
- At-least-once delivery with LSN feedback after Kafka flush

## Production Enhancements (Post-MVP)

### Already Implemented âœ…
- âœ… LSN tracking with at-least-once delivery guarantee
- âœ… Replication slot auto-creation and management
- âœ… Transaction boundary handling (BEGIN/COMMIT internally)
- âœ… Graceful shutdown with signal handlers (SIGINT, SIGTERM)
- âœ… Configuration validation on startup
- âœ… Fail-fast error handling with supervisor restart
- âœ… Relation registry for table metadata (auto-rebuilds on restart)

### Planned Improvements ðŸ“‹

**Snapshot Support:**
- Initial snapshot before streaming replication starts
- Consistent point-in-time data capture
- Handle large tables with pagination

**Advanced Data Types:**
- PostgreSQL-specific types (JSON, arrays, JSONB)
- TOAST value handling for large objects
- Custom type support

**Monitoring and Observability:**
- Metrics for replication lag and throughput
- Health checks for slot status and connection
- Structured metrics export (Prometheus format)

**Schema Change Handling:**
- Detect DDL changes via RELATION messages
- Invalidate cached metadata automatically
- Handle column additions/removals gracefully